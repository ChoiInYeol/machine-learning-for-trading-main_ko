# 거래를 위한 텍스트 데이터: 감정 분석

이 내용은 자연어 처리(NLP)와 기계 학습을 사용하여 텍스트 데이터에서 알고리즘 거래 전략에 대한 신호를 추출하는 데 전념하는 세 장 중 첫 번째입니다.

텍스트 데이터는 콘텐츠가 매우 풍부하지만 구조화되어 있지 않으므로 ML 알고리즘을 사용하여 관련 정보를 추출하려면 더 많은 전처리가 필요합니다. 핵심 과제는 의미를 잃지 않고 텍스트를 숫자 형식으로 변환하는 것입니다. ML 알고리즘의 입력으로 사용할 수 있도록 언어의 뉘앙스를 포착할 수 있는 여러 기술을 다룰 것입니다.

이 장에서는 개별 의미 단위, 즉 단어나 토큰이라는 짧은 단어 그룹에 초점을 맞춘 기본적인 특징 추출 기술을 소개합니다. 문서 용어 행렬을 생성하여 문서를 토큰 수의 벡터로 표현한 다음 이를 뉴스 분류 및 감정 분석을 위한 입력으로 사용하는 방법을 보여줍니다. 이러한 목적으로 인기가 있는 Naive Bayes 알고리즘도 소개하겠습니다.

다음 두 장에서는 이러한 기술을 기반으로 주제 모델링 및 단어 벡터 임베딩과 같은 ML 알고리즘을 사용하여 더 넓은 맥락에 포함된 정보를 캡처합니다.

## 콘텐츠

1. __자리표시자_0__
    * __자리표시자_1__
    * __자리표시자_2__
    * __자리표시자_3__
2. __자리표시자_4__
    * __자리표시자_5__
        - __자리표시자_6__
    * __자리표시자_7__
3. __자리표시자_8__
    * __자리표시자_9__
4. __자리표시자_10__
    * __자리표시자_11__
    * __자리표시자_12__
    * __자리표시자_13__
        - __자리표시자_14__
        - __자리표시자_15__

## 텍스트 데이터를 사용한 ML - 언어부터 기능까지

인간이 자연어를 사용하여 전달하고 저장하는 정보의 양을 고려할 때 텍스트 데이터는 매우 중요할 수 있습니다. 투자와 관련된 다양한 데이터 소스는 회사 명세서, 계약서, 특허 등의 공식 문서부터 뉴스, 의견, 분석가 연구 또는 논평, 다양한 유형의 소셜 미디어 게시물 또는 메시지에 이르기까지 다양합니다.

유용한 리소스는 다음과 같습니다.

- [음성 및 언어 처리](https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf), Daniel Jurafsky 및 James H. Martin, 3판, 초안, 2018
- [통계적 자연어 처리 및 코퍼스 기반 전산언어학](https://nlp.stanford.edu/links/statnlp.html), 주석이 달린 리소스 목록, Stanford University
- __자리표시자_18__

### 자연어 처리의 과제

구조화되지 않은 텍스트를 기계가 읽을 수 있는 형식으로 변환하려면 데이터의 중요한 의미 측면을 보존하기 위해 신중한 전처리가 필요합니다. 인간이 언어의 내용에서 의미를 도출하고 이해하는 방법은 완전히 이해되지 않았으며 기계의 언어 이해를 향상시키는 것은 여전히 ​​매우 활발한 연구 분야입니다.

기계 학습을 위해 텍스트 데이터를 효과적으로 사용하려면 언어의 내부 작동에 대한 이해와 언어가 참조하는 세계에 대한 지식이 필요하기 때문에 NLP는 어렵습니다. 주요 과제는 다음과 같습니다.
- 다의어로 인한 모호성, 즉 단어나 문구가 문맥에 따라 다른 의미를 가질 수 있음('지역 고등학교 중퇴자 절반 감소')
- 특히 소셜 미디어에서 비표준적이고 진화하는 언어 사용
- 숙어: '수건을 던져라'
- 엔터티 이름은 까다로울 수 있습니다. 'A Bug's Life는 어디에서 플레이되나요?'
- 세상에 대한 지식의 필요성: '메리와 수는 자매이다' vs '메리와 수는 엄마다'

### 사용 사례

| 사용 사례 | 설명 | 예 |
|---|---|---|
| 챗봇 | 사용자의 자연어를 이해하고 지능적인 응답 반환 | __자리표시자_19__ |
| 정보 검색 | 관련 결과 및 유사한 결과 찾기 | __자리표시자_20__ |
| 정보 추출 | 구조화되지 않은 문서의 구조화된 정보 | __자리표시자_21__ |
| 기계 번역 | 한 언어에서 다른 언어로 | __자리표시자_22__ |
| 텍스트 단순화 | 텍스트의 의미는 유지하되 문법과 어휘는 단순화 | __자리 표시자_23__, __자리 표시자_24__ |
| 예측 텍스트 입력 | 더 빠르고 쉬운 타이핑 | __자리 표시자_25__, __자리 표시자_26__ |
| 감성분석 | 발표자의 태도 | __자리표시자_27__ |
| 자동 요약 | 추출적 또는 추상적 요약 | __자리 표시자_28__, __자리 표시자_29__ |
| 자연어 생성 | 데이터에서 텍스트 생성 | __자리 표시자_30__, __자리 표시자_31__ |
| 음성 인식 및 생성 | 음성-텍스트, 텍스트-음성 | __자리 표시자_32__, __자리 표시자_33__ |
| 질문 답변 | 질문의 의도를 파악하고, 쿼리를 지식 기반과 연결하고, 가설을 평가합니다 | __자리 표시자_34__, __자리 표시자_35__, __자리 표시자_36__

### NLP 워크플로우

알고리즘 거래를 위해 텍스트 데이터에서 기계 학습을 사용하는 주요 목표는 문서에서 신호를 추출하는 것입니다. 문서는 관련 텍스트 데이터 소스의 개별 샘플입니다. 회사 보고서, 헤드라인이나 뉴스 기사, 트윗 등이 있습니다. 코퍼스는 문서의 모음입니다.
다음 그림은 문서를 실행 가능한 예측을 할 수 있는 지도 기계 학습 알고리즘을 훈련하는 데 사용할 수 있는 데이터세트로 변환하는 주요 단계를 보여줍니다.

<p 정렬="중앙">
<img src="https://i.imgur.com/LPxpc8D.png" width="90%">
</p>

## 텍스트에서 토큰까지 – NLP 파이프라인

다음 표에는 NLP 파이프라인의 주요 작업이 요약되어 있습니다.

| 기능 | 설명 |
|------------------|------ ------------------------------------------------|
| 토큰화 | 텍스트를 단어, 구두점 등으로 분할합니다. |
| 품사 태깅 | 동사나 명사와 같은 단어 유형을 토큰에 할당합니다.                 |
| 종속성 분석 | subject <=> 객체와 같은 구문 토큰 종속성에 라벨을 붙입니다.      |
| 형태소 분석 및 원형 분석 | 단어의 기본 형태를 지정하십시오: "was" => "be", "rats" => "rat".   |
| 문장 경계 감지 | 개별 문장을 찾아 분류하세요.                            |
| 명명된 엔터티 인식 | 사람, 회사 또는 위치와 같은 "실제" 개체에 라벨을 붙입니다. |
| 유사성 | 단어, 텍스트 범위 및 문서의 유사성을 평가합니다.          |

### 코드 예: spaCy 및 textacy가 포함된 NLP 파이프라인

노트북 [nlp_pipeline_with_spaCy](01_nlp_pipeline_with_spaCy.ipynb)은 오픈 소스 Python 라이브러리 [스파시]((https://spacy.io/))를 사용하여 NLP 파이프라인을 구성하는 방법을 보여줍니다. [문자 메시지](https://chartbeat-labs.github.io/textacy/index.html) 라이브러리는 spaCy를 기반으로 하며 spaCy 속성 및 추가 기능에 대한 쉬운 액세스를 제공합니다.

- spaCy [문서](https://spacy.io/) 및 설치 [지침](https://spacy.io/usage/#installation)
- textacy는 추가 NLP 작업을 해결하기 위해 `spaCy`에 의존합니다. - [선적 서류 비치](https://chartbeat-labs.github.io/textacy/index.html)를 참조하세요.

#### 데이터
- [BBC 기사](http://mlg.ucd.ie/datasets/bbc.html), 원시 텍스트 파일 사용
- [TED2013](http://opus.nlpl.eu/TED2013.php), 15개 언어로 된 TED 강연 자막 병렬 코퍼스

### 코드 예: TextBlob을 사용한 NLP

`TextBlob` 라이브러리는 품사 태깅, 명사구 추출, 감정 분석, 분류, 번역 등을 포함한 일반적인 NLP 작업을 위한 단순화된 인터페이스를 제공합니다.

[nlp_with_textblob](02_nlp_with_textblob.ipynb) 노트북은 해당 기능을 보여줍니다.

- __자리표시자_46__
- __자리표시자_47__

좋은 대안은 인간 언어 데이터로 작업할 Python 프로그램을 구축하기 위한 선도적인 플랫폼인 NLTK입니다. 분류, 토큰화, 형태소 분석, 태그 지정, 구문 분석 및 의미 추론을 위한 텍스트 처리 라이브러리 제품군, 업계 최고의 NLP 라이브러리용 래퍼, WordNet과 같은 50개 이상의 말뭉치 및 어휘 리소스에 대한 사용하기 쉬운 인터페이스를 제공합니다. 그리고 활발한 토론 포럼.

- 자연어 도구 키트(NLTK) [선적 서류 비치](http://www.nltk.org/)

## 토큰 계산 – 문서 용어 매트릭스

이 섹션에서는 텍스트 데이터를 거리를 사용하여 문서를 비교할 수 있는 숫자 벡터 공간 표현으로 변환하는 단어주머니 모델을 소개합니다. sklearn 라이브러리를 사용하여 문서 용어 행렬을 만드는 방법을 보여줍니다.

- __자리표시자_49__

### 코드 예: scikit-learn을 사용한 문서 용어 행렬

scikit-learn 전처리 모듈은 문서 용어 매트릭스를 생성하는 두 가지 도구를 제공합니다. 
1. [카운트벡터라이저](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)은 이진 또는 절대 개수를 사용하여 각 문서 d 및 토큰 t에 대한 용어 빈도 tf(d, t)를 측정합니다.
2. 대조적으로 [TfIDF벡터화기](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)은 역 문서 빈도(idf)로 (절대) 용어 빈도에 가중치를 둡니다. 결과적으로 더 많은 문서에 나타나는 용어는 특정 문서에 대해 빈도는 동일하지만 모든 문서에서 빈도가 낮은 토큰보다 낮은 가중치를 받게 됩니다.

[document_term_matrix](03_document_term_matrix.ipynb) 노트북은 사용법과 구성을 보여줍니다.

## 거래를 위한 NLP: 텍스트 분류 및 감정 분석

이전 섹션에서 설명한 자연어 처리 기술을 사용하여 텍스트 데이터가 수치 특성으로 변환되면 텍스트 분류는 다른 분류 작업과 동일하게 작동합니다.

이 섹션에서는 이러한 전처리 기술을 뉴스 기사, 제품 리뷰 및 Twitter 데이터에 적용하고 다양한 분류자를 가르쳐 개별 뉴스 카테고리, 리뷰 점수 및 정서 극성을 예측하도록 하겠습니다.

먼저 Bag-of-Words 모델에서 생성된 텍스트 특징과 잘 작동하는 확률적 분류 알고리즘인 Naive Bayes 모델을 소개합니다.

- [일일 시장 뉴스 심리 및 주가](https://www.econstor.eu/handle/10419/125094), David E. Allen & Michael McAleer & Abhay K. Singh, 2015, Tinbergen Institute 토론 문서
- [감정 구성을 사용하여 웹 텍스트에서 경제 지표 예측](http://www.ijcce.org/index.php?m=content&c=index&a=show&catid=39&id=358), Abby Levenberg 외, 2014
- __자리표시자_55__

### 나이브 베이즈 분류기

Naive Bayes 알고리즘은 계산 비용이 낮고 메모리 요구 사항이 매우 크고 고차원 데이터 세트에 대한 훈련을 용이하게 하기 때문에 텍스트 분류에 매우 널리 사용됩니다. 예측 성능은 더 복잡한 모델과 경쟁할 수 있고 좋은 기준선을 제공하며 성공적인 스팸 탐지로 가장 잘 알려져 있습니다.

이 모델은 베이즈 정리와 주어진 결과 클래스에 따라 다양한 특성이 서로 독립적이라는 가정에 의존합니다. 즉, 주어진 결과에 대해 한 기능의 가치(예: 문서에 토큰의 존재)를 아는 것은 다른 기능의 가치에 대한 정보를 제공하지 않습니다.

### 코드 예: 뉴스 기사 분류

우리는 Naive Bayes 모델의 그림으로 시작하여 우리가 알고 있는 2,225개의 BBC 뉴스 기사를 5개의 다른 범주에 분류합니다.

노트북 [텍스트_분류](04_text_classification.ipynb)에는 관련 예제가 포함되어 있습니다.

### 코드 예시: 감정 분석

감정 분석은 자산이나 기타 가격 동인에 대한 긍정적 또는 부정적 관점이 수익에 영향을 미칠 가능성이 높기 때문에 거래를 위해 자연어 처리 및 기계 학습을 가장 널리 사용하는 것 중 하나입니다.

일반적으로 감정 분석에 대한 모델링 접근 방식은 사전을 TextBlob 라이브러리로 사용하거나 특정 도메인의 결과에 대해 훈련된 모델을 사용합니다. 후자는 보다 표적화된 라벨링을 허용하기 때문에 바람직합니다. 간접적인 감정 점수보다는 텍스트 기능을 후속 가격 변화에 연결합니다.

데이터를 얻는 방법에 대한 지침은 [데이터](../data) 디렉터리를 참조하세요.

#### 바이너리 분류: 트위터 데이터

우리는 이진 극성 레이블이 있는 [트위터 데이터세트](http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip)과 5점 결과 척도가 있는 대규모 Yelp 비즈니스 리뷰 데이터 세트를 사용하여 감정 분석을 위한 기계 학습을 설명합니다.

노트북 [감정_분석_트위터](05_sentiment_analysis_twitter.ipynb)에는 관련 예제가 포함되어 있습니다.

- __자리표시자_60__

#### 대규모 멀티클래스 Yelp 데이터에 대한 다양한 ML 알고리즘 비교

더 큰 규모의 텍스트 처리 및 분류를 설명하기 위해 [Yelp 데이터세트](https://www.yelp.com/dataset)도 사용합니다.

노트북 [감정_분석_yelp](06_sentiment_analysis_yelp.ipynb)에는 관련 예제가 포함되어 있습니다.

- __자리 표시자__ 63 __