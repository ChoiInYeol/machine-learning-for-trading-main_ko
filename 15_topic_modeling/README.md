# 수익 창출 통화 및 금융 뉴스를 위한 주제 모델링

이 장에서는 비지도 기계 학습을 사용하여 문서에서 잠재 주제를 추출합니다. 이러한 테마는 자동화된 방식으로 대규모 문서 본문에 대한 자세한 통찰력을 제공할 수 있습니다. 주제와 문서의 연관성 정도를 이용하므로 건초더미 자체를 이해하고 문서에 간결한 태깅을 허용하는 데 매우 유용합니다.

주제 모델을 사용하면 대규모 문서 모음에서 거래 신호를 추출하는 데 다양한 방법으로 사용할 수 있는 정교하고 해석 가능한 텍스트 기능을 추출할 수 있습니다. 문서 검토 속도를 높이고, 유사한 문서를 식별 및 클러스터링하는 데 도움을 주며, 예측 모델링의 기초로 주석을 달 수 있습니다. 응용 프로그램에는 회사 공개 또는 수익 보고 기록, 고객 리뷰 또는 계약의 주요 주제 식별, 예를 들어 감정 분석을 사용하여 주석을 달거나 후속 자산 반환에 대한 직접 라벨링이 포함됩니다. 보다 구체적으로, 이 장에서는 다음 내용을 다룰 것입니다.

## 콘텐츠

1. __자리표시자_0__
2. __자리표시자_1__
    * __자리표시자_2__
3. __자리표시자_3__
    * __자리표시자_4__
4. __자리표시자_5__
    * __자리표시자_6__
    * __자리표시자_7__
    * __자리표시자_8__
    * __자리표시자_9__
    * __자리표시자_10__
    * __자리표시자_11__
5. __자리표시자_12__
6. __자리표시자_13__
7. __자리표시자_14__
    * __자리표시자_15__
    * __자리표시자_16__

## 잠재 주제 학습: 목표 및 접근 방식

벡터 공간 모델(1970년대 중반에 개발됨)을 개선하려는 주제 모델의 초기 시도는 선형 대수학을 적용하여 문서 용어 행렬의 차원성을 줄였습니다. 이 접근 방식은 비지도 학습에 관한 12장에서 주성분 분석으로 논의한 알고리즘과 유사합니다. 효과적이긴 하지만 벤치마크 모델 없이 이러한 모델의 결과를 평가하는 것은 어렵습니다.

이에 대응하여 명시적인 문서 생성 프로세스를 가정하고 이 프로세스를 리버스 엔지니어링하고 기본 주제를 복구하는 알고리즘을 제공하는 확률 모델이 등장했습니다.

아래 표는 다음 섹션에서 더 자세히 다룰 모델 발전의 주요 이정표를 강조합니다.

| 모델 | 연도 | 설명 |
|---------------------|- -----|------------------ ------------------------------------- -----------------|
| LSI(잠재 의미 색인) | 1988 | 단어 공간의 차원을 줄여 의미론적 문서-용어 관계 포착 |
| pLSA(확률적 잠재 의미 분석) | 1999 | 단어가 주제를 생성하고 주제의 혼합으로 문서를 생성한다고 가정하는 생성 프로세스를 리버스 엔지니어링합니다.
| 잠재 디리클레 할당(LDA) | 2003년 | 문서에 대한 생성 프로세스를 추가합니다: 3단계 계층, 베이지안 모델 |

## LSI(잠재 의미 색인)

잠재 의미 분석은 쿼리 용어의 동의어가 포함된 해당 문서를 생략한 쿼리의 결과를 개선하는 데 착수했습니다. 단어 사용의 가변성으로 인해 그러한 연관성이 관찰되지 않더라도 용어가 문서와 연관되어야 함을 예측할 수 있도록 문서와 용어 간의 관계를 모델링하는 것이 목표입니다.

LSI는 선형 대수학을 사용하여 DTM을 분해하여 주어진 수 k의 잠재 주제를 찾습니다. 보다 구체적으로, 특이값 분해(SVD)를 사용하여 k개의 특이값 및 벡터를 사용하여 가장 낮은 순위의 DTM 근사치를 찾습니다. 즉, LSI는 12장에서 다룬 차원 축소의 비지도 학습 기술(추가 세부 사항 포함)을 적용한 것입니다. 저자는 계층적 클러스터링을 실험했지만 문서-주제 및 주제-용어 관계를 명시적으로 모델링하거나 여러 주제가 있는 문서 또는 용어의 연관성을 포착하는 것이 너무 제한적이라는 것을 발견했습니다.

### 코드 예: scikit-learn을 사용하여 LSI를 구현하는 방법

[latent_semantic_indexing](01_latent_semantic_indexing.ipynb) 노트북은 지난 장에서 사용한 BBC 새 기사에 LSI를 적용하는 방법을 보여줍니다.

## pLSA(확률적 잠재 의미 분석)

pLSA(확률적 잠재 의미 분석)는 LSA에 대한 통계적 관점을 취하고 LSA의 이론적 기반 부족을 해결하기 위한 생성 모델을 만듭니다.

pLSA는 주제 t를 포함하는 조건부 독립 다항 분포의 혼합으로 DTM에서 설명하는 문서 d와 단어 w의 각 동시 발생 확률을 명시적으로 모델링합니다. 주제 수는 훈련 전에 선택된 하이퍼파라미터이며 데이터에서 학습되지 않습니다.

### 코드 예: scikit-learn을 사용하여 pLSA를 구현하는 방법
 
The notebook [확률_잠재_분석](02_probabilistic_latent_analysis.ipynb) demonstrates how to apply LSI to the BBC new articles we used in the last chapter.

- [PLSA와 NMF의 관계와 시사점](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.70.8839&rep=rep1&type=pdf), Gaussier, Goutte, 2005

## LDA(잠재 디리클레 할당)

잠재 Dirichlet 할당은 주제에 대한 생성 프로세스를 추가하여 pLSA를 확장합니다.
이는 인간이 관련시킬 수 있고 새 문서에 주제를 할당할 수 있으며 확장 가능한 의미 있는 주제를 생성하는 경향이 있기 때문에 가장 인기 있는 주제 모델입니다. LDA 모델의 변형은 작성자와 같은 메타데이터를 포함하거나 이미지 데이터를 포함하거나 계층적 주제를 학습할 수 있습니다.

LDA는 주제가 단어에 대한 확률 분포이고 문서가 주제에 대한 분포라고 가정하는 계층적 베이지안 모델입니다. 보다 구체적으로, 모델은 주제가 희박한 Dirichlet 분포를 따른다고 가정합니다. 이는 문서가 작은 주제 집합만 다루고 주제는 작은 단어 집합만 자주 사용함을 의미합니다.

### 코드 예: Dirichlet 분포

Dirichlet 분포는 이산 분포와 함께 사용할 수 있는 확률 벡터를 생성합니다. 즉, 주어진 수의 양수 값과 합이 1이 되는 값을 무작위로 생성합니다. 확률의 집중을 제어하는 ​​양의 실수 값 매개변수 𝜶가 있습니다.

노트북 [디리클레_분포](03_dirichlet_distribution.ipynb)에는 다양한 매개변수 값을 실험해 볼 수 있는 시뮬레이션이 포함되어 있습니다.

### LDA 주제를 평가하는 방법

비지도 주제 모델은 결과가 의미가 있거나 해석 가능하다는 보장을 제공하지 않으며 지도 학습처럼 결과를 평가할 객관적인 측정 기준이 없습니다. 인간 주제 평가는 '최적 표준'으로 간주되지만 잠재적으로 비용이 많이 들고 대규모로 쉽게 사용할 수 없습니다.

결과를 보다 객관적으로 평가하는 두 가지 옵션에는 보이지 않는 문서에 대한 모델을 평가하는 당혹성(perplexity)과 발견된 패턴의 의미론적 품질을 평가하는 것을 목표로 하는 주제 일관성 지표가 포함됩니다.

### 코드 예: scikit-learn을 사용하여 LDA를 구현하는 방법

[lda_with_sklearn](04_lda_with_sklearn.ipynb) 노트북은 BBC 뉴스 기사에 LDA를 적용하는 방법을 보여줍니다. 우리는 [sklearn.decomposition.LatentDirichletAllocation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)를 사용하여 5가지 주제로 LDA 모델을 교육합니다.

### pyLDAvis를 사용하여 LDA 결과를 시각화하는 방법

주제 시각화는 인간의 판단을 사용하여 주제 품질 평가를 용이하게 합니다. pyLDAvis는 R 및 D3.js로 개발된 LDAvis의 Python 포트입니다. 핵심 개념을 소개하겠습니다. 각 LDA 구현 노트북에는 예제가 포함되어 있습니다.

pyLDAvis는 주제 간의 글로벌 관계를 표시하는 동시에 각 개별 주제와 가장 밀접하게 연관된 용어와 반대로 각 용어와 연관된 주제를 검사하여 의미론적 평가를 촉진합니다. 또한 말뭉치에서 자주 사용되는 용어가 주제를 정의하는 단어보다 다항 분포를 지배하는 경향이 있는 문제를 해결합니다. LDAVis는 가중치 매개변수 0<=τ<=1을 사용하여 주요 용어의 유연한 순위를 생성하기 위해 용어 w의 관련성 r을 주제 t에 도입합니다.

- [저자의 이야기](https://speakerdeck.com/bmabey/visualizing-topic-models) 및 [(원본) 저자의 논문](http://www.aclweb.org/anthology/W14-3110)
- __자리표시자_25__

### 코드 예: gensim을 사용하여 LDA를 구현하는 방법

Gensim은 빠른 LDA 구현과 다양한 추가 기능을 갖춘 전문 NLP 라이브러리입니다. 또한 다음 장에서 단어 벡터를 배우기 위해 이를 사용할 것입니다(자세한 내용은 [lda_with_gensim](05_lda_with_gensim.ipynb) 노트북을 참조하세요.

### 참고자료

- __자리표시자_27__
- [소개 논문](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf) 및 [추가 기술 검토 논문](http://www.cs.columbia.edu/~blei/papers/BleiLafferty2009.pdf)
- __자리표시자_30__
- __자리표시자_31__
- __자리표시자_32__
- __자리표시자_33__

## 코드 예: 수입 결산 중에 논의된 모델링 주제

[대체 데이터](../03_alternative_data/02_earnings_calls)의 3장에서는 SeekingAlpha 사이트에서 수입 결산 데이터를 긁어내는 방법을 배웠습니다.

이 섹션에서는 이 소스를 사용한 주제 모델링을 설명합니다. 저는 2018년과 2019년의 약 700개 수익 보고 기록 샘플을 사용하고 있습니다([데이터](../data) 디렉토리 참조). 이는 상당히 작은 샘플입니다. 실제 적용을 위해서는 더 큰 데이터 세트가 필요합니다.  
 
노트북 [lda_earnings_calls](06_lda_earnings_calls.ipynb)에는 데이터 로드, 탐색, 사전 처리는 물론 다양한 모델 학습 및 평가에 대한 세부 정보가 포함되어 있습니다.

## 코드 예: 금융 뉴스 기사를 사용한 주제 모델링

__PLACEHOLDER__ 37 ____ 노트북은 LDA를 사용하여 Reuters 및 기타 업체(출처는 __PLACEHOLDER__ 38 _ 참조)에서 제공한 대규모 금융 뉴스 기사 모음을 요약하는 방법을 보여줍니다.

## 자원

### 응용

- [주제 모델의 응용](https://mimno.infosci.cornell.edu/papers/2017_fntir_tm_applications.pdf), Jordan Boyd-Graber, Yuening Hu, David Mimno, 2017
- __자리표시자_40__
- __자리표시자_41__
- __자리표시자_42__
- __자리표시자_43__

### 주제 모델링 라이브러리

- __자리표시자_44__
- __자리표시자_45__