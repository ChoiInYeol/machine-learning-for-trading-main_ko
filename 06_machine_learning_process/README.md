# 머신러닝 워크플로

이 장에서는 거래에 다양한 지도 및 비지도 기계 학습(ML) 모델을 사용하는 방법을 설명하는 이 책의 2부로 시작합니다. 다양한 Python 라이브러리를 사용하여 관련 애플리케이션을 시연하기 전에 각 모델의 가정과 사용 사례를 설명하겠습니다. 2~4부에서 다룰 모델 범주는 다음과 같습니다.

- 단면, 시계열, 패널 데이터의 회귀 및 분류를 위한 선형 모델
- 의사결정 트리와 같은 비선형 트리 기반 모델을 포함한 일반화된 추가 모델
- 랜덤 포레스트 및 그래디언트 부스팅 머신을 포함한 앙상블 모델
- 차원 축소 및 클러스터링을 위한 비지도 선형 및 비선형 방법
- 순환 및 컨벌루션 아키텍처를 포함한 신경망 모델
- 강화 학습 모델

우리는 이 모델을 이 책의 첫 번째 부분에서 소개한 시장, 기본 및 대체 데이터 소스에 적용할 것입니다. 우리는 모델 신호를 거래로 변환하는 거래 전략에 이러한 모델을 포함시키는 방법, 포트폴리오를 최적화하는 방법, 전략 성과를 평가하는 방법을 시연함으로써 지금까지 다룬 자료를 토대로 구축할 것입니다.

이러한 모델과 해당 응용 프로그램에는 몇 가지 공통점이 있습니다. 이 장에서는 다음 장에서 모델별 사용법에 집중할 수 있도록 이러한 일반적인 측면을 다룹니다. 여기에는 목적 함수 또는 손실 함수를 최적화하여 데이터로부터 기능적 관계를 학습한다는 중요한 목표가 포함됩니다. 또한 모델 성능을 측정하는 밀접하게 관련된 방법도 포함됩니다.

우리는 비지도 학습과 지도 학습을 구별하고 알고리즘 거래에 대한 사용 사례를 간략하게 설명합니다. 우리는 지도 회귀 및 분류 문제, 입력 데이터와 출력 데이터 간의 관계에 대한 통계적 추론을 위한 지도 학습 사용과 미래 출력 예측을 위한 지도 학습 사용을 대조합니다. 또한 예측 오류가 모델의 편향이나 분산으로 인해 발생하거나 데이터의 높은 잡음 대 신호 비율로 인해 발생하는 방식도 설명합니다. 가장 중요한 것은 과적합과 같은 오류의 원인을 진단하고 모델 성능을 향상시키는 방법을 제시한다는 것입니다.

이미 ML에 대해 잘 알고 있다면 앞으로 건너뛰고 ML 모델을 사용하여 알고리즘 거래 전략을 위한 알파 팩터를 생성하고 결합하는 방법을 바로 배우십시오.

## 콘텐츠

1. __자리표시자_0__
    * __자리표시자_1__
    * __자리표시자_2__
    * __자리표시자_3__
        - __자리표시자_4__
    * __자리표시자_5__
2. __자리표시자_6__
    * __자리표시자_7__
3. __자리표시자_8__
4. __자리표시자_9__
5. __자리표시자_10__
    * __자리표시자_11__
6. __자리표시자_12__
7. __자리표시자_13__
    * __자리표시자_14__
8. __자리표시자_15__
    * __자리표시자_16__
9. __자리표시자_17__
    * __자리표시자_18__
    * __자리표시자_19__
10. __자리표시자_20__
    * __자리표시자_21__

## 데이터를 통한 머신러닝 작동 방식

ML에 대한 많은 정의는 데이터에서 의미 있는 패턴을 자동으로 감지하는 것을 중심으로 이루어집니다. 두 가지 대표적인 예는 다음과 같습니다.
- AI 선구자 Arthur Samuelson은 1959년에 ML을 명시적으로 프로그래밍하지 않고도 컴퓨터에 학습 기능을 제공하는 컴퓨터 과학의 하위 분야로 정의했습니다. 
- 현재 이 분야의 리더 중 한 명인 Tom Mitchell은 1998년에 잘 제기된 학습 문제를 보다 구체적으로 지적했습니다. 컴퓨터 프로그램은 작업과 관련된 경험과 작업 성능이 향상되는지 여부에 대한 성과 측정을 통해 학습합니다. 경험(Mitchell, 1997).

경험은 훈련 데이터의 형태로 알고리즘에 제시됩니다. 문제를 해결하는 기계를 구축하려는 이전 시도와의 주요 차이점은 알고리즘이 결정을 내리는 데 사용하는 규칙이 예를 들어 1980년대에 두드러진 전문가 시스템의 경우처럼 인간에 의해 프로그래밍되는 것이 아니라 데이터에서 학습된다는 것입니다. .

광범위한 알고리즘과 일반 응용 분야를 다루는 권장 교과서는 다음과 같습니다. 
- [통계 학습 소개](http://faculty.marshall.usc.edu/gareth-james/ISL/), 제임스 외 (2013)
- [통계적 학습의 요소: 데이터 마이닝, 추론 및 예측](https://web.stanford.edu/~hastie/ElemStatLearn/), Hastie, Tibshirani, Friedman (2009)
- [패턴 인식 및 기계 학습](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf), 비숍(2006)
- [기계 학습](http://www.cs.cmu.edu/~tom/mlbook.html), 미첼(1997).

### 핵심 과제: 주어진 작업에 적합한 알고리즘 찾기

자동화된 학습의 주요 과제는 모델의 학습을 새로운 데이터로 일반화할 때 의미 있는 훈련 데이터의 패턴을 식별하는 것입니다. 모델이 식별할 수 있는 잠재적인 패턴은 많이 있지만 훈련 데이터는 알고리즘이 향후 작업을 수행할 때 직면할 수 있는 더 큰 현상 집합의 샘플일 뿐입니다.

### 지도 학습: 예시를 통해 과제 가르치기

지도 학습은 가장 일반적으로 사용되는 ML 유형입니다. 우리는 이 책의 대부분의 장을 이 범주의 응용 프로그램에 할애할 것입니다. 지도라는 용어는 학습 과정을 안내하는 결과 변수의 존재를 의미합니다. 즉, 알고리즘에 당면 과제에 대한 올바른 솔루션을 가르칩니다. 지도 학습의 목표는 이 관계를 반영하는 개별 샘플에서 기능적 입출력 관계를 포착하고 새로운 데이터에 대한 유효한 설명을 작성하여 학습을 적용하는 것입니다.

### 비지도 학습: 데이터를 탐색하여 유용한 패턴 식별

비지도 학습 문제를 해결할 때 우리는 특징만 관찰하고 결과를 측정하지 않습니다. 비지도 알고리즘은 미래 결과를 예측하거나 변수 간의 관계를 추론하는 대신 데이터에 포함된 정보의 새로운 표현을 허용하는 입력의 구조를 식별하는 것을 목표로 합니다.

#### 거래전략 적용대상: 위험관리부터 처리까지
비지도 학습에 대한 수많은 거래 사용 사례가 있으며 이후 장에서 다룰 것입니다.
- 유사한 위험 및 수익 특성을 지닌 증권을 그룹화합니다([13장의 계층적 위험 동등성](../13_unsupervised_learning/04_hierarchical_risk_parity) 참조).
- [주요 구성 요소 분석](../13_unsupervised_learning/01_linear_dimensionality_reduction)) 또는 자동 인코더([제20장](../20_autoencoders_for_conditional_risk_factors))를 사용하여 훨씬 더 많은 수의 증권의 성능을 좌우하는 소수의 위험 요소를 찾습니다.
- 해당 문서의 가장 중요한 측면을 구성하는 문서 본문(예: 수익 보고 기록)에서 숨겨진 주제 식별([제15장](../15_topic_modeling))

### 강화 학습: 한 번에 한 단계씩 수행하여 학습

강화 학습(RL)은 ML의 세 번째 유형입니다. 이는 환경에서 제공되는 정보를 기반으로 각 시간 단계에서 작업을 선택해야 하는 에이전트에 중점을 둡니다. 에이전트는 자율주행차일 수도 있고, 보드 게임이나 비디오 게임을 하는 프로그램일 수도 있고, 특정 보안 시장에서 운영되는 거래 전략일 수도 있습니다.

2018년 [서튼과 바토](http://www.incompleteideas.net/book/the-book-2nd.html)에서 훌륭한 소개를 찾을 수 있습니다.

## 머신러닝 워크플로

ML 솔루션을 개발하려면 효율적으로 진행하면서 성공 가능성을 극대화하기 위한 체계적인 접근 방식이 필요합니다. 협업, 유지 관리 및 후속 개선을 촉진하기 위해 프로세스를 투명하고 복제 가능하게 만드는 것도 중요합니다.

이 프로세스는 전체적으로 반복되며 다양한 단계의 노력은 프로젝트에 따라 달라집니다. 그럼에도 불구하고 이 프로세스에는 일반적으로 다음 단계가 포함되어야 합니다.

1. 문제의 틀을 잡고, 목표 지표를 식별하고, 성공을 정의합니다.
2. 데이터 소싱, 정리, 검증
3. 데이터를 이해하고 유용한 기능을 생성합니다.
4. 데이터에 적합한 하나 이상의 기계 학습 알고리즘을 선택하세요.
5. 모델 학습, 테스트 및 조정
6. 모델을 사용하여 원래 문제를 해결하세요.

### 코드 예: K-최근접 이웃을 사용한 ML 워크플로

[machine_learning_workflow](01_machine_learning_workflow.ipynb) 노트북에는 간단한 주택 가격 데이터 세트를 사용하여 기계 학습 워크플로를 설명하는 몇 가지 예가 포함되어 있습니다.

- sklearn [선적 서류 비치](http://scikit-learn.org/stable/documentation.html)
- k-최근접 이웃 [지도 시간](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn) 및 [심상](http://vision.stanford.edu/teaching/cs231n-demos/knn/)

## 문제의 틀 잡기: 목표 및 지표

모든 기계 학습 연습의 출발점은 해결하려는 궁극적인 사용 사례입니다. 때로는 이 목표가 변수 간의 연관성이나 인과 관계를 식별하기 위한 통계적 추론일 수도 있습니다. 그러나 대부분의 경우 목표는 거래 신호를 생성하는 결과를 직접 예측하는 것입니다.

## 데이터 수집 및 준비

우리는 [제 2 장](../02_market_and_fundamental_data)에서 시장 및 기본 데이터의 소싱을 다루고 [3 장](../03_alternative_data)에서 대체 데이터에 대해 다루었습니다. 우리는 이후 장에서 다양한 모델의 적용을 설명하면서 이러한 소스의 다양한 예제를 계속해서 작업할 것입니다.

## 기능을 탐색, 추출 및 엔지니어링하는 방법

개별 변수의 분포와 결과 및 특징 간의 관계를 이해하는 것은 적합한 알고리즘을 선택하는 기초입니다. 이는 일반적으로 동반 노트북에 설명된(다음 이미지에 표시됨) 분산형 차트와 같은 시각화로 시작하지만 상관 관계와 같은 선형 측정항목부터 Spearman 순위 상관 관계와 같은 비선형 통계에 이르는 수치 평가도 포함합니다. 정보 계수를 소개할 때 만난 계수입니다. 또한 상호정보와 같은 정보이론적 측정도 포함됩니다.

### 코드 예: 상호 정보

[상호 정보](02_mutual_information.ipynb) 노트북은 [알파 요인 – 연구 및 평가]((../04_alpha_factor_research) 장의 [기능_엔지니어링](../04_alpha_factor_research/00_data/feature_engineering.ipynb) 노트북에서 생성한 재무 데이터에 정보 이론을 적용합니다.

## ML 알고리즘 선택

이 책의 나머지 부분에서는 입력 변수와 출력 변수 간의 기능적 관계의 본질에 대해 상당히 강력한 가정을 하는 선형 모델부터 가정을 거의 하지 않는 심층 신경망에 이르기까지 여러 모델 계열을 소개합니다.

## 모델 설계 및 조정

ML 프로세스에는 모델의 일반화 오류 추정치를 기반으로 모델 복잡성을 진단하고 관리하는 단계가 포함됩니다. 편향되지 않은 추정에는 통계적으로 타당하고 효율적인 절차뿐만 아니라 출력 변수 유형과 일치하는 오류 측정항목이 필요합니다. 이는 회귀, 분류 또는 순위 문제를 처리하는지 여부도 결정합니다.

### 코드 예: 편향-분산 절충

새로운 입력 데이터의 결과를 예측할 때 ML 모델이 저지르는 오류는 축소 가능한 부분과 축소 불가능한 부분으로 분류될 수 있습니다. 환원 불가능한 부분은 관련이 있지만 누락된 변수 또는 자연적 변동과 같이 측정되지 않은 데이터의 무작위 변동(노이즈)으로 인해 발생합니다.

노트북 [편향_분산](03_bias_variance.ipynb)은 점점 더 복잡해지는 다항식을 사용하여 코사인 함수를 근사하고 샘플 내 오류를 측정하여 과적합을 보여줍니다.  다양한 복잡성의 다항식을 학습하기 위해 약간의 노이즈(n = 30)가 추가된 10개의 무작위 샘플을 추출합니다. 매번 모델은 새로운 데이터 포인트를 예측하고 이러한 예측에 대한 평균 제곱 오류와 이러한 오류의 표준 편차를 캡처합니다. 계속해서 약간의 노이즈가 추가된 9차 코사인 함수의 테일러 급수 근사를 학습하여 과적합과 과소적합의 영향을 설명합니다. 다음 다이어그램에서는 실제 함수의 무작위 샘플을 추출하고 과소적합, 과적합 및 대략 정확한 정도의 유연성을 제공하는 다항식을 피팅합니다.

## 모델 선택에 교차 검증을 사용하는 방법

사용 사례에 여러 후보 모델(즉, 알고리즘)을 사용할 수 있는 경우 그 중 하나를 선택하는 행위를 모델 선택 문제라고 합니다. 모델 선택은 새로운 데이터가 주어지면 가장 낮은 예측 오류를 생성하는 모델을 식별하는 것을 목표로 합니다.

### 코드 예: Python에서 교차 검증을 구현하는 방법

[교차 검증](04_cross_validation.py) 스크립트는 10개의 관측값이 있는 모의 데이터세트의 인덱스가 학습 및 테스트 세트에 할당되는 방법을 보여줌으로써 데이터를 학습 및 테스트 세트로 분할하는 다양한 옵션을 보여줍니다.
 
## scikit-learn을 개별적으로 사용하기 위해

모델 선택에는 일반적으로 다양한 알고리즘(예: 선형 회귀 및 랜덤 포레스트) 또는 다양한 구성을 사용하여 모델의 표본 외 성능에 대한 반복적인 교차 검증이 포함됩니다. 다양한 구성에는 하이퍼파라미터 변경이나 다양한 변수의 포함 또는 제외가 포함될 수 있습니다.

### 코드 예: 노란색 벽돌이 있는 학습 및 검증 곡선

노트북 [machine_learning_workflow](01_machine_learning_workflow.ipynb))에서는 학습 사용을 보여주고 검증은 다양한 모델 선택 기술의 사용을 보여줍니다.

- Yellowbrick: 기계 학습 시각화 [문서](http://www.scikit-yb.org/en/latest/)

### 코드 예: GridSearchCV 및 파이프라인을 사용한 매개변수 조정

초매개변수 조정은 기계 학습 워크플로의 핵심 요소이므로 이 프로세스를 자동화하는 도구가 있습니다. sklearn 라이브러리에는 모든 매개변수 조합을 병렬로 교차 검증하고, 결과를 캡처하고, 전체 데이터 세트에 대한 교차 검증 중에 가장 잘 수행된 매개변수 설정을 사용하여 모델을 자동으로 교육하는 GridSearchCV 인터페이스가 포함되어 있습니다.

실제로 훈련 및 검증 세트에는 교차 검증 전에 일부 처리가 필요한 경우가 많습니다. Scikit-learn은 GridSearchCV를 통해 촉진되는 자동화된 하이퍼파라미터 튜닝에서 필요한 기능 처리 단계를 자동화하는 파이프라인도 제공합니다.

포함된 machine_learning_workflow.ipynb 노트북의 구현 예제를 통해 이러한 도구가 실제로 작동하는 모습을 볼 수 있습니다.

노트북 [machine_learning_workflow](01_machine_learning_workflow.ipynb))도 이러한 도구의 사용을 보여줍니다.

## 금융 분야의 교차 검증 문제

지금까지 논의된 교차 검증 방법에 대한 주요 가정은 훈련에 사용할 수 있는 샘플의 독립적이고 동일한(iid) 분포입니다.
금융 데이터의 경우에는 그렇지 않은 경우가 많습니다. 반대로 금융 데이터는 이분산성이라고도 알려진 계열 상관관계와 시변 표준편차로 인해 독립적이거나 동일하게 분포되지 않습니다.

### 퍼지, 금지 및 조합 CV

재무 데이터의 경우 수익률이 여러 기간의 가격에서 계산되므로 라벨은 중복되는 데이터 포인트에서 파생되는 경우가 많습니다. 거래 전략의 맥락에서 자산에 대한 포지션을 취하는 것을 암시할 수 있는 모델 예측 결과는 나중에 이 결정이 평가될 때(예: 포지션이 청산될 때)만 알 수 있습니다.

결과적인 위험에는 테스트에서 훈련 세트로의 정보 유출이 포함되며, 이로 인해 인위적으로 성능이 부풀려질 수 있으며 모든 데이터가 특정 시점, 즉 해당 시점에 실제로 사용 가능하고 알려져 있는지 확인하여 해결해야 합니다. 이는 모델의 입력으로 사용됩니다. 교차 검증을 위한 재무 데이터의 이러한 문제를 해결하기 위해 Marcos Lopez de Prado가 [금융 머신러닝의 발전](https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089)에서 제안한 몇 가지 방법이 있습니다.

- 제거: 예견 편향을 피하기 위해 검증 세트에서 특정 시점 데이터 포인트를 예측한 후 평가가 발생하는 훈련 데이터 포인트를 제거합니다.
- 금지: 테스트 기간 이후의 훈련 샘플을 추가로 제거합니다.