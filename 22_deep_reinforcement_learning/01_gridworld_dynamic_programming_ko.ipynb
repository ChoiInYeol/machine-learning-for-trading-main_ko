{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 동적 프로그래밍: 가치 및 정책 반복"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 섹션에서는 다음 기능과 함께 다음 다이어그램에 묘사된 3 x 4 그리드로 구성된 장난감 환경에 값과 정책 반복을 적용합니다.",
        "\n",
        "- **상태**: 2차원 좌표로 표현된 11가지 상태입니다. 한 필드는 액세스할 수 없으며 가장 오른쪽 열의 상위 두 상태는 터미널 상태입니다. 즉, 에피소드가 종료됩니다.",
        "- **액션**: 각 단계, 즉 위, 아래, 왼쪽, 오른쪽으로 이동합니다. 환경은 무작위로 지정되어 있어 행동이 의도하지 않은 결과를 초래할 수 있습니다. 각 행동마다 예상된 상태로 이동할 확률은 80%이고, 인접한 방향(예: 위쪽이 아닌 오른쪽 또는 왼쪽, 오른쪽이 아닌 위쪽 또는 아래쪽)으로 이동할 확률은 10%입니다.",
        "- **보상**: 오른쪽 패널에 표시된 것처럼 터미널 상태의 +1/-1 보상을 제외하고 각 상태의 결과는 -.02입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"../assets/mdp.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이전 GridWorld 다이어그램의 오른쪽 패널은 Value Iteration과 해당 탐욕 정책에 의해 생성된 최적의 추정 가치를 보여줍니다. 환경의 불확실성과 결합된 부정적인 보상은 부정적인 최종 상태에서 벗어나는 것을 포함하는 최적의 정책을 생성합니다.",
        "\n",
        "결과는 보상과 할인 요인 모두에 민감합니다. 부정적인 상태의 비용은 주변 필드의 정책에 영향을 미치며, 최적의 작업 선택을 변경하는 임계값 수준을 식별하려면 해당 노트북의 예를 수정해야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 가져오기 및 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.458379Z",
          "start_time": "2021-02-25T05:53:53.163752Z"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from time import process_time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mdptoolbox import mdp\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 그리드월드 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 상태, 행동, 보상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "환경 매개변수를 정의하는 것부터 시작하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.461605Z",
          "start_time": "2021-02-25T05:53:53.459473Z"
        }
      },
      "outputs": [],
      "source": [
        "grid_size = (3, 4)\n",
        "blocked_cell = (1, 1)\n",
        "baseline_reward = -0.02\n",
        "absorbing_cells = {(0, 3): 1, (1, 3): -1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.471257Z",
          "start_time": "2021-02-25T05:53:53.462755Z"
        }
      },
      "outputs": [],
      "source": [
        "actions = ['L', 'U', 'R', 'D']\n",
        "num_actions = len(actions)\n",
        "probs = [.1, .8, .1, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1차원 표현과 2차원 표현 사이를 변환해야 하는 경우가 자주 있으므로 이 목적을 위해 두 가지 도우미 함수를 정의하겠습니다. 상태는 1차원이고 셀은 해당하는 2차원 좌표입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.480216Z",
          "start_time": "2021-02-25T05:53:53.472202Z"
        }
      },
      "outputs": [],
      "source": [
        "to_1d = lambda x: np.ravel_multi_index(x, grid_size)\n",
        "to_2d = lambda x: np.unravel_index(x, grid_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "또한 코드를 더욱 간결하게 만들기 위해 일부 데이터 포인트를 미리 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.488588Z",
          "start_time": "2021-02-25T05:53:53.481077Z"
        }
      },
      "outputs": [],
      "source": [
        "num_states = np.product(grid_size)\n",
        "cells = list(np.ndindex(grid_size))\n",
        "states = list(range(len(cells)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.501520Z",
          "start_time": "2021-02-25T05:53:53.489468Z"
        }
      },
      "outputs": [],
      "source": [
        "cell_state = dict(zip(cells, states))\n",
        "state_cell= dict(zip(states, cells))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.514770Z",
          "start_time": "2021-02-25T05:53:53.502395Z"
        }
      },
      "outputs": [],
      "source": [
        "absorbing_states = {to_1d(s):r for s, r in absorbing_cells.items()}\n",
        "blocked_state = to_1d(blocked_cell)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "우리는 각 상태에 대한 보상을 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.522796Z",
          "start_time": "2021-02-25T05:53:53.516107Z"
        }
      },
      "outputs": [],
      "source": [
        "state_rewards = np.full(num_states, baseline_reward)\n",
        "state_rewards[blocked_state] = 0\n",
        "for state, reward in absorbing_states.items():\n",
        "    state_rewards[state] = reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.533539Z",
          "start_time": "2021-02-25T05:53:53.523763Z"
        }
      },
      "outputs": [],
      "source": [
        "action_outcomes = {}\n",
        "for i, action in enumerate(actions):\n",
        "    probs_ = dict(zip([actions[j % 4] for j in range(i, num_actions + i)], probs))\n",
        "    action_outcomes[actions[(i + 1) % 4]] = probs_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "확률적 환경을 설명하기 위해 주어진 행동에 대한 실제 움직임에 대한 확률 분포도 계산해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.556370Z",
          "start_time": "2021-02-25T05:53:53.538534Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'U': {'L': 0.1, 'U': 0.8, 'R': 0.1, 'D': 0},\n",
              " 'R': {'U': 0.1, 'R': 0.8, 'D': 0.1, 'L': 0},\n",
              " 'D': {'R': 0.1, 'D': 0.8, 'L': 0.1, 'U': 0},\n",
              " 'L': {'D': 0.1, 'L': 0.8, 'U': 0.1, 'R': 0}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "action_outcomes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제 MDP의 주요 입력인 전환 행렬을 계산할 준비가 되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 전환 매트릭스"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "전이 행렬은 각 이전 상태 및 동작 A에 대해 특정 상태 S로 끝날 확률을 $P(s^\\prime \\mid s, a)$로 정의합니다. `pymdptoolbox`을 시연하고 전환 및 보상을 지정하는 데 사용할 수 있는 형식 중 하나를 사용합니다. 두 가지 전환 확률에 대해 $A \\times S \\times S$ 차원의 `NumPy` 배열을 만듭니다.",
        "\n",
        "먼저, 각 시작 셀에 대한 대상 셀을 계산하고 이동합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.568063Z",
          "start_time": "2021-02-25T05:53:53.561297Z"
        }
      },
      "outputs": [],
      "source": [
        "def get_new_cell(state, move):\n",
        "    cell = to_2d(state)\n",
        "    if actions[move] == 'U':\n",
        "        return cell[0] - 1, cell[1]\n",
        "    elif actions[move] == 'D':\n",
        "        return cell[0] + 1, cell[1]\n",
        "    elif actions[move] == 'R':\n",
        "        return cell[0], cell[1] + 1\n",
        "    elif actions[move] == 'L':\n",
        "        return cell[0], cell[1] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.581908Z",
          "start_time": "2021-02-25T05:53:53.569841Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.02, -0.02, -0.02,  1.  , -0.02,  0.  , -0.02, -1.  , -0.02,\n",
              "       -0.02, -0.02, -0.02])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "다음 함수는 인수의 시작 `state`, `action` 및 `outcome`을 사용하여 전환 확률과 보상을 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.589775Z",
          "start_time": "2021-02-25T05:53:53.583446Z"
        }
      },
      "outputs": [],
      "source": [
        "def update_transitions_and_rewards(state, action, outcome):\n",
        "    if state in absorbing_states.keys() or state == blocked_state:\n",
        "        transitions[action, state, state] = 1\n",
        "    else:\n",
        "        new_cell = get_new_cell(state, outcome)\n",
        "        p = action_outcomes[actions[action]][actions[outcome]]\n",
        "        if new_cell not in cells or new_cell == blocked_cell:\n",
        "            transitions[action, state, state] += p\n",
        "            rewards[action, state, state] = baseline_reward\n",
        "        else:\n",
        "            new_state= to_1d(new_cell)\n",
        "            transitions[action, state, new_state] = p\n",
        "            rewards[action, state, new_state] = state_rewards[new_state]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "다음과 같이 자리 표시자 데이터 구조를 만들고 $A \\times S \\times S$의 데카르트 곱을 반복하여 전환 및 보상 값을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.599667Z",
          "start_time": "2021-02-25T05:53:53.591026Z"
        }
      },
      "outputs": [],
      "source": [
        "rewards = np.zeros(shape=(num_actions, num_states, num_states))\n",
        "transitions = np.zeros((num_actions, num_states, num_states))\n",
        "actions_ = list(range(num_actions))\n",
        "for action, outcome, state in product(actions_, actions_, states):\n",
        "    update_transitions_and_rewards(state, action, outcome)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.608614Z",
          "start_time": "2021-02-25T05:53:53.600900Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 12, 12), (4, 12, 12))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rewards.shape, transitions.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyMDP 도구 상자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q-학습을 포함하여 몇 가지 추가 알고리즘이 포함된 [pymdp도구 상자](https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html) Python 라이브러리를 사용하여 MDP를 해결할 수도 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 가치 반복"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.617034Z",
          "start_time": "2021-02-25T05:53:53.609777Z"
        }
      },
      "outputs": [],
      "source": [
        "gamma = .99\n",
        "epsilon = 1e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`ValueIteration`을 실행하려면 `.run()` 메서드를 호출하기 전에 원하는 구성 옵션과 보상 및 전환 행렬을 사용하여 해당 객체를 인스턴스화하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.629694Z",
          "start_time": "2021-02-25T05:53:53.617943Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Iterations: 31 | Time: 0.0006'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vi = mdp.ValueIteration(transitions=transitions,\n",
        "                        reward=rewards,\n",
        "                        discount=gamma,\n",
        "                        epsilon=epsilon)\n",
        "\n",
        "vi.run()\n",
        "f'# Iterations: {vi.iter:,d} | Time: {vi.time:.4f}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.641404Z",
          "start_time": "2021-02-25T05:53:53.630625Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3\n",
              "0  R  R  R  L\n",
              "1  U  L  U  L\n",
              "2  U  L  L  L"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "policy = np.asarray([actions[i] for i in vi.policy])\n",
        "pd.DataFrame(policy.reshape(grid_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.652654Z",
          "start_time": "2021-02-25T05:53:53.642553Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.884143</td>\n",
              "      <td>0.925054</td>\n",
              "      <td>0.961986</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.848181</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714643</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.808345</td>\n",
              "      <td>0.773328</td>\n",
              "      <td>0.736099</td>\n",
              "      <td>0.516083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3\n",
              "0  0.884143  0.925054  0.961986  0.000000\n",
              "1  0.848181  0.000000  0.714643  0.000000\n",
              "2  0.808345  0.773328  0.736099  0.516083"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value = np.asarray(vi.V).reshape(grid_size)\n",
        "pd.DataFrame(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 정책 반복"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`PolicyIteration` 함수도 비슷하게 작동합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.716943Z",
          "start_time": "2021-02-25T05:53:53.653609Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Iterations: 7 | Time: 0.0560'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pi = mdp.PolicyIteration(transitions=transitions,\n",
        "                        reward=rewards,\n",
        "                        discount=gamma,\n",
        "                        max_iter=1000)\n",
        "\n",
        "pi.run()\n",
        "f'# Iterations: {pi.iter:,d} | Time: {pi.time:.4f}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "또한 동일한 정책을 생성하지만 가치 함수는 실행마다 다르며 정책이 수렴되기 전에 최적의 값을 달성할 필요가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.726528Z",
          "start_time": "2021-02-25T05:53:53.717726Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3\n",
              "0  R  R  R  L\n",
              "1  U  L  U  L\n",
              "2  U  L  L  L"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "policy = np.asarray([actions[i] for i in pi.policy])\n",
        "pd.DataFrame(policy.reshape(grid_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.737898Z",
          "start_time": "2021-02-25T05:53:53.727643Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.884143</td>\n",
              "      <td>0.925054</td>\n",
              "      <td>0.961986</td>\n",
              "      <td>-1.389785e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.848181</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.714643</td>\n",
              "      <td>5.749281e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.808345</td>\n",
              "      <td>0.773328</td>\n",
              "      <td>0.736099</td>\n",
              "      <td>5.160828e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2             3\n",
              "0  0.884143  0.925054  0.961986 -1.389785e-16\n",
              "1  0.848181  0.000000  0.714643  5.749281e-16\n",
              "2  0.808345  0.773328  0.736099  5.160828e-01"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value = np.asarray(pi.V).reshape(grid_size)\n",
        "pd.DataFrame(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 가치 반복"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.746078Z",
          "start_time": "2021-02-25T05:53:53.739535Z"
        }
      },
      "outputs": [],
      "source": [
        "skip_states = list(absorbing_states.keys())+[blocked_state]\n",
        "states_to_update = [s for s in states if s not in skip_states]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "그런 다음 가치 함수를 초기화하고 할인 계수 감마와 수렴 임계값 엡실론을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.754465Z",
          "start_time": "2021-02-25T05:53:53.747205Z"
        }
      },
      "outputs": [],
      "source": [
        "V = np.random.rand(num_states)\n",
        "V[skip_states] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.763120Z",
          "start_time": "2021-02-25T05:53:53.755441Z"
        }
      },
      "outputs": [],
      "source": [
        "gamma = .99\n",
        "epsilon = 1e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "알고리즘은 Bellman 최적성 방정식을 사용하여 가치 함수를 업데이트하고 V의 L1 노름이 절대값으로 엡실론보다 적게 변경될 때 종료됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.774651Z",
          "start_time": "2021-02-25T05:53:53.764814Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Iterations 24 | Time 0.0023'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iterations = 0\n",
        "start = process_time()\n",
        "converged = False\n",
        "while not converged:\n",
        "    V_ = np.copy(V)\n",
        "    for state in states_to_update:\n",
        "        q_sa = np.sum(transitions[:, state] * (rewards[:, state] + gamma* V), axis=1)\n",
        "        V[state] = np.max(q_sa)\n",
        "    if np.sum(np.fabs(V - V_)) < epsilon:\n",
        "        converged = True\n",
        "\n",
        "    iterations += 1\n",
        "    if iterations % 1000 == 0:\n",
        "        print(np.sum(np.fabs(V - V_)))\n",
        "\n",
        "f'# Iterations {iterations} | Time {process_time() - start:.4f}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 가치 기능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.784869Z",
          "start_time": "2021-02-25T05:53:53.776099Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          0         1         2         3\n",
            "0  0.884143  0.925054  0.961986  0.000000\n",
            "1  0.848181  0.000000  0.714643  0.000000\n",
            "2  0.808345  0.773328  0.736099  0.516083\n"
          ]
        }
      ],
      "source": [
        "print(pd.DataFrame(V.reshape(grid_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.793712Z",
          "start_time": "2021-02-25T05:53:53.785673Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.allclose(V.reshape(grid_size), np.asarray(vi.V).reshape(grid_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 최적의 정책"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.802251Z",
          "start_time": "2021-02-25T05:53:53.794660Z"
        },
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for state, reward in absorbing_states.items():\n",
        "    V[state] = reward\n",
        "\n",
        "policy = np.argmax(np.sum(transitions * V, 2),0)\n",
        "policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.814636Z",
          "start_time": "2021-02-25T05:53:53.803107Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3\n",
              "0  R  R  R  L\n",
              "1  U  L  L  L\n",
              "2  U  L  L  L"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(policy.reshape(grid_size)).replace(dict(enumerate(actions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 정책 반복"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "정책 반복에는 별도의 평가 및 개선 단계가 포함됩니다. 기대 보상과 다음 상태 가치의 합을 최대화하는 행동을 선택하여 개선 부분을 정의합니다. 우리를 최종 상태로 이끄는 행동을 무시하지 않기 위해 일시적으로 최종 상태에 대한 보상을 채웁니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.827609Z",
          "start_time": "2021-02-25T05:53:53.815647Z"
        }
      },
      "outputs": [],
      "source": [
        "def policy_improvement(value, transitions):\n",
        "    for state, reward in absorbing_states.items():\n",
        "        value[state] = reward\n",
        "    return np.argmax(np.sum(transitions * value, 2),0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.848053Z",
          "start_time": "2021-02-25T05:53:53.828806Z"
        }
      },
      "outputs": [],
      "source": [
        "V = np.random.rand(num_states)\n",
        "V[skip_states] = 0\n",
        "pi = np.random.choice(list(range(num_actions)), size=num_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "알고리즘은 정책이 안정화될 때까지 탐욕스럽게 선택한 작업에 대한 정책 평가와 정책 개선을 번갈아 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.865229Z",
          "start_time": "2021-02-25T05:53:53.849041Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Iterations 3 | Time 0.0009'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iterations = 0\n",
        "start = process_time()\n",
        "converged = False\n",
        "while not converged:\n",
        "    pi_ = np.copy(pi)\n",
        "    for state in states_to_update:\n",
        "        action = policy[state]\n",
        "        V[state] = np.dot(transitions[action, state], (rewards[action, state] + gamma* V))\n",
        "        pi = policy_improvement(V.copy(), transitions)\n",
        "    if np.array_equal(pi_, pi):\n",
        "        converged = True\n",
        "    iterations += 1\n",
        "\n",
        "f'# Iterations {iterations} | Time {process_time() - start:.4f}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "정책 반복은 단 세 번의 반복 후에 수렴됩니다. 정책은 알고리즘이 최적의 가치 함수를 찾기 전에 안정화되며 최적의 정책은 약간 다릅니다. 특히 음의 최종 상태 옆에 있는 필드에 대해 더 안전한 왼쪽 대신 위쪽을 제안함으로써 가장 두드러집니다. 이는 예를 들어 여러 라운드의 안정적인 정책을 요구하거나 가치 함수에 대한 임계값을 추가하는 등 수렴 기준을 강화함으로써 방지할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.875788Z",
          "start_time": "2021-02-25T05:53:53.866220Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>R</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3\n",
              "0  R  R  R  L\n",
              "1  U  L  U  L\n",
              "2  U  L  L  L"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(pi.reshape(grid_size)).replace(dict(enumerate(actions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-25T05:53:53.887239Z",
          "start_time": "2021-02-25T05:53:53.876852Z"
        },
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.756333</td>\n",
              "      <td>0.882232</td>\n",
              "      <td>0.933790</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.683594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.480169</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.612364</td>\n",
              "      <td>0.552599</td>\n",
              "      <td>0.506767</td>\n",
              "      <td>0.307299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3\n",
              "0  0.756333  0.882232  0.933790  0.000000\n",
              "1  0.683594  0.000000  0.480169  0.000000\n",
              "2  0.612364  0.552599  0.506767  0.307299"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(V.reshape(grid_size))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}