# 거래를 위한 RNN: 다변량 시계열 및 텍스트 데이터

RNN의 주요 혁신은 각 출력이 이전 출력과 새 데이터의 함수라는 것입니다. 결과적으로 RNN은 이전 관찰에 대한 정보를 새로운 특징 벡터에 대해 수행하는 계산에 통합하여 메모리가 있는 모델을 효과적으로 생성하는 기능을 얻습니다. 이 반복 공식을 통해 주기를 포함하는 훨씬 더 깊은 계산 그래프에서 매개변수 공유가 가능합니다. 대표적인 아키텍처로는 오류가 여러 연결을 통해 전파되어야 하는 장거리 종속성 학습과 관련된 그래디언트 소멸 문제를 극복하는 것을 목표로 하는 LSTM(Long Short-Term Memory) 및 GRU(Gated Recurrent Unit)가 있습니다.

RNN은 하나 이상의 입력 시퀀스를 하나 이상의 출력 시퀀스에 매핑해야 하는 다양한 작업에 성공적으로 적용되었으며 특히 자연어에 매우 적합합니다. RNN은 시장 또는 기본 데이터를 예측하기 위해 단변량 및 다변량 시계열에도 적용할 수 있습니다. 이 장에서는 문서에 표현된 감정을 분류하기 위해 RNN이 [제16장](16_word_embeddings)에서 다룬 단어 임베딩을 사용하여 대체 텍스트 데이터를 모델링하는 방법을 다룹니다.

## 콘텐츠

1. __자리표시자_1__
    * __자리표시자_2__
    * __자리표시자_3__
        - __자리표시자_4__
        - __자리 표시자_5__
2. __자리표시자_6__
    * __자리표시자_7__
    * __자리표시자_8__
    * __자리표시자_9__
    * __자리표시자_10__
3. __자리표시자_11__
    * __자리표시자_12__
    * __자리표시자_13__
    * __자리표시자_14__

## 순환 신경망의 작동 방식

RNN은 이전 데이터 포인트가 현재 관찰에 영향을 미치고 후속 값을 예측하는 데 관련되도록 입력 데이터가 시퀀스로 생성되었다고 가정합니다. 따라서 주어진 수의 계산 단계를 사용하여 하나의 입력 벡터를 하나의 출력 벡터에 매핑하도록 설계된 FFNN 및 CNN보다 더 복잡한 입출력 관계를 허용합니다. 
이와 대조적으로 RNN은 입력, 출력 또는 둘 다가 벡터 시퀀스로 가장 잘 표현되는 작업에 대한 데이터를 모델링할 수 있습니다.

전체 개요는 Goodfellow, Bengio 및 Courville(2016)의 [10장](https://www.deeplearningbook.org/contents/rnn.html in [Deep Learning](https://www.deeplearningbook.org/)을 참조하세요.

### 시간에 따른 역전파

RNN은 출력이 이전 반복의 결과에 따라 달라지는 방식으로 시퀀스의 모든 요소에 동일한 변환을 적용하기 때문에 반복이라고 합니다. 결과적으로 RNN은 메모리와 유사한 시퀀스의 이전 요소에 대한 정보를 캡처하는 내부 상태를 유지합니다.

매개변수에 대한 손실 함수의 기울기를 기반으로 가중치 매개변수를 업데이트하는 역전파 알고리즘은 펼쳐진 계산 그래프를 따라 왼쪽에서 오른쪽으로 순방향 전달을 수행한 후 반대 방향으로 역방향 전달을 수행합니다.

- [시퀀스 모델링: 순환 및 재귀 네트](http://www.deeplearningbook.org/contents/rnn.html), 딥 러닝 북, 10장, Ian Goodfellow, Yoshua Bengio 및 Aaron Courville, MIT Press, 2016
- [순환 신경망을 사용한 감독된 시퀀스 라벨링](https://www.cs.toronto.edu/~graves/preprint.pdf), 알렉스 그레이브스, 2013
- [LSTM 순환 네트워크에 대한 튜토리얼](http://people.idsia.ch/~juergen/lstm/sld001.htm), Juergen Schmidhuber, 2003
- __자리표시자_19__

### 대체 RNN 아키텍처

RNN은 입력 데이터와 출력 데이터 간의 기능적 관계와 동적 관계를 가장 잘 포착하기 위해 다양한 방식으로 설계될 수 있습니다. 숨겨진 상태 간의 반복 연결 외에도 반복 출력 관계, 양방향 RNN 및 인코더-디코더 아키텍처를 포함한 여러 가지 대체 접근 방식이 있습니다.

#### 장단기 기억

LSTM 아키텍처를 사용하는 RNN은 내부 상태를 유지하고 입력 시퀀스 요소 간의 종속성을 추적하고 그에 따라 셀 상태를 조절하는 게이트를 포함하는 더 복잡한 장치를 가지고 있습니다. 이 게이트는 위에서 접한 일반적인 숨겨진 유닛 대신 서로 반복적으로 연결됩니다. 그들은 그라디언트가 변경되지 않은 상태로 통과되도록 하여 그라디언트가 사라지고 폭발하는 문제를 해결하는 것을 목표로 합니다.

일반적인 LSTM 유닛은 벡터를 변환하고 전달하여 서로 상호 작용하고 셀 상태와 상호 작용하는 4개의 매개변수화된 레이어를 결합합니다. 이러한 레이어에는 일반적으로 입력 게이트, 출력 게이트 및 망각 게이트가 포함되지만 추가 게이트가 있거나 이러한 메커니즘 중 일부가 부족한 변형도 있습니다.

- [LSTM 네트워크 이해](http://colah.github.io/posts/2015-08-Understanding-LSTMs/), 크리스토퍼 올라, 2015
- [순환 네트워크 아키텍처에 대한 실증적 탐구](http://proceedings.mlr.press/v37/jozefowicz15.pdf), Rafal Jozefowicz, Ilya Sutskever 외, 2015

#### 게이트 순환 단위

GRU(Gated Recurrent Unit)는 출력 게이트를 생략하여 LSTM 장치를 단순화합니다. 특정 언어 모델링 작업에서는 유사한 성능을 달성하지만 더 작은 데이터 세트에서는 더 나은 성능을 보이는 것으로 나타났습니다.

- __placeholder_22__, K halo GH 및 NC ho, yo 브러시 Ben GI Oh, ETA 2014
- __placeholder_23__, 정준영, CA 관리 arg UL 기획 Re, K halo GH 및 NC 호, 요 브러쉬 Ben GI Oh, 2014

## TensorFlow 2를 사용한 금융 시계열용 RNN

다양한 시나리오에 대해 Keras 라이브러리를 사용하여 RNN을 구축하는 방법을 설명합니다. 첫 번째 모델 세트에는 일변량 및 다변량 시계열의 회귀 및 분류가 포함됩니다. 두 번째 작업 세트는 단어 임베딩으로 변환된 텍스트 데이터를 사용하여 감정 분석을 위한 텍스트 데이터에 중점을 둡니다([제15장](../15_word_embeddings) 참조).

- __자리표시자_25__
- __자리표시자_26__
- __자리표시자_27__
- __자리표시자_28__
- [RNN 작업](https://keras.io/guides/working_with_rnns/) - Scott Zhu 및 Francois Chollet 제작

### 코드 예: 일변량 시계열 회귀: S&P 500 예측

[univariate_time_series_regression](01_univariate_time_series_regression.ipynb) 노트북은 데이터를 필요한 형태로 가져오는 방법과 순환 신경망을 사용하여 S&P 500 지수 값을 예측하는 방법을 보여줍니다.

### 코드 예: 주간 주가 변동 및 수익률 예측을 위한 누적 LSTM

이제 Quandl 주가 데이터를 사용하여 두 개의 LSTM 레이어를 쌓아서 좀 더 심층적인 모델을 구축하겠습니다. 또한 본질적으로 순차적이지 않은 기능, 즉 월, 연도와 같은 기간 및 티커를 식별하는 표시 변수를 포함합니다.
- 구현 세부정보는 [stacked_lstm_with_feature_embeddings](02_stacked_lstm_with_feature_embeddings.ipynb) 노트북을 참조하세요.

### 코드 예: 방향성 가격 이동 대신 수익 예측

[stacked_lstm_with_feature_embeddings_regression](03_stacked_lstm_with_feature_embeddings_regression.ipynb) 노트북은 바이너리 가격 변화가 아닌 수익을 예측하는 회귀 작업에 모델을 적용하는 방법을 보여줍니다.

### 코드 예: 매크로 데이터에 대한 다변량 시계열 회귀

지금까지 우리는 모델링 노력을 단일 시계열로 제한했습니다. RNN은 당연히 다변량 시계열에 매우 적합하며 [9장 시계열 모델](../09_time_series_models)에서 다룬 벡터 자동 회귀(VAR) 모델에 대한 비선형 대안을 나타냅니다.

[다변량_시계열](04_multivariate_timeseries.ipynb) 노트북은 [VAR 예시](../09_time_series_models/04_vector_autoregressive_model.ipynb)에 사용한 것과 동일한 데이터세트, 즉 소비자 심리에 대한 월별 데이터와 연방준비은행 FRED 서비스의 산업 생산을 사용하여 여러 시계열을 모델링하고 예측하는 데 RNN을 적용하는 방법을 보여줍니다.

## 텍스트 데이터를 위한 RNN: 감정 분석 및 반환 예측

### 코드 예: 감정 분류를 위한 사용자 정의 단어 임베딩이 포함된 LSTM

RNN은 일반적으로 다양한 자연어 처리 작업에 적용됩니다. 우리는 이미 [이 책](https://www.amazon.com/Machine-Learning-Algorithmic-Trading-alternative/dp/1839217715?pf_rd_r=VMKJPZC4N36TTZZCWATP&pf_rd_p=c5b6893a-24f2-4a59-9d4b-aff5065c90ec&pd_rd_r=8f331266-0d21-4c76-a3eb-d2e61d23bb31&pd_rd_w=kVGNF&pd_rd_wg=LYLKH&ref_=pd_gw_ci_mcx_mr_hp_d)의 3부에서 텍스트 데이터를 사용한 감정 분석을 접했습니다.

이 예에서는 분류 작업에 대해 RNN을 훈련하면서 사용자 정의 임베딩 벡터를 학습하는 방법을 보여줍니다. 이는 이웃 토큰의 예측을 최적화하면서 벡터를 학습하여 단어 간의 특정 의미 관계를 포착할 수 있는 word2vec 모델과 다릅니다(16장 참조). 감정 예측을 목표로 단어 벡터를 학습한다는 것은 임베딩이 토큰이 연결된 결과와 어떻게 관련되는지를 반영한다는 것을 의미합니다.

노트북 [감정_분석_imdb](05_sentiment_analysis_imdb.ipynb)은 RNN 모델을 텍스트 데이터에 적용하여 긍정적이거나 부정적인 감정을 감지하는 방법을 보여줍니다(세분된 감정 규모로 쉽게 확장 가능). 문서의 토큰을 표현하기 위해 단어 임베딩을 사용할 것입니다. [15장. 단어 임베딩](../15_word_embeddings)에서 단어 임베딩을 다루었습니다. 이는 잠재 공간에서 단어의 상대적 위치가 문맥에서 단어의 사용법을 기반으로 유용한 의미 측면을 인코딩하도록 텍스트를 연속 벡터 표현으로 변환하는 탁월한 기술입니다.

### 코드 예: 사전 학습된 단어 벡터를 사용한 감정 분석

[15장. 단어 임베딩](../15_word_embeddings)에서는 도메인별 단어 임베딩을 학습하는 방법을 보여주었습니다. Word2vec 및 관련 학습 알고리즘은 고품질 단어 벡터를 생성하지만 대규모 데이터 세트가 필요합니다. 따라서 연구 그룹은 [이전 장](../17_convolutional_neural_nets)의 전이 학습 섹션에서 접한 사전 훈련된 딥 러닝 모델의 가중치와 유사하게 대규모 데이터 세트에서 훈련된 단어 벡터를 공유하는 것이 일반적입니다.

[감정_분석_사전 훈련된_임베딩](06_sentiment_analysis_pretrained_embeddings.ipynb) 노트북은 IMDB 검토 데이터 세트와 함께 Stanford NLP 그룹에서 제공하는 사전 훈련된 GloVe(Global Vector for Word Representation)를 사용하는 방법을 보여줍니다.

- [대규모 영화 리뷰 데이터세트](http://ai.stanford.edu/~amaas/data/sentiment/), 스탠포드 AI 그룹
- [GloVe: 단어 표현을 위한 전역 벡터](https://nlp.stanford.edu/projects/glove/), 스탠포드 NLP

### 코드 예: 주간 수익을 예측하기 위한 양방향 RNN GRU에 대한 SEC 제출

16장에서는 제품 리뷰와 금융 텍스트 데이터의 중요한 차이점을 논의했습니다. 전자는 중요한 작업 흐름을 설명하는 데 유용했지만, 이 섹션에서는 더 까다로우면서도 관련성이 높은 재무 문서를 다룰 것입니다.

보다 구체적으로, 우리는 [제16장](../16_word_embeddings)에 도입된 SEC 제출 데이터를 사용하여 공개 전부터 일주일 후까지 공개와 관련된 티커의 반환을 예측하는 데 맞춤화된 단어 임베딩을 학습할 것입니다.

노트북 __PLACEHOLDER__ 45 __에는 이 애플리케이션에 대한 코드 예제가 포함되어 있습니다.

데이터를 얻는 방법에 대해서는 16장의 노트북 [sec_전처리](../16_word_embeddings/06_sec_preprocessing.ipynb)과 GitHub의 데이터 폴더에 있는 지침을 참조하세요.